---
title: CS294-131 Fall 2018
layout: default
---

## Instructors

<div class="instructor">
  <a href="https://people.eecs.berkeley.edu/~trevor/">
  <div class="instructorphoto"><img src="trevordarrell.jpg"></div>
  <div>Trevor Darrell</div>
  </a>
</div>
<div class="instructor">
  <a href="https://people.eecs.berkeley.edu/~dawnsong/">
  <div class="instructorphoto"><img src="johncanny.png"></div>
  <div>John Canny
  </div>
  </a>

</div>

## Teaching Assistants

<div class="instructor">
  <a href="https://people.eecs.berkeley.edu/~coline/">
  <div class="instructorphoto"><img src="colinedevin.jpg" height="140" width="140"></div>
  <div>Coline Devin
  </div>
  </a>
</div>

## Office Hours

Coline Devin: By appointment

## Lectures

**Time**: Tuesday 12:30-1:59pm

**Location**: Soda 306

## Piazza

Course announcements will be announced through Piazza. If you are in the class,
[**sign up on Piazza**])(https://piazza.com/class/jl5o7zd1s439l).

##Syllabus
<table style="table-layout: fixed; font-size: 88%;">
  <thead>
    <tr>
      <th style="width: 5%;">Date</th>
      <th style="width: 17%;">Speaker</th>
      <th style="width: 50%;">Readings</th>
      <th style="width: 15%;">Talk</th>
      <th style="width: 15%;">Deadlines</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>08/28</td>
      <td>Nicholas Carlini</td>
      <td><u>Main Reading:</u>
      <ul>
	<li>https://arxiv.org/pdf/1802.00420.pdf</li>
	<li>https://arxiv.org/pdf/1802.05666.pdf</li>
      </ul>
      <u>Background Reading:</u>
      <ul>
	<li>https://arxiv.org/pdf/1706.06083.pdf</li>
	<li>https://arxiv.org/pdf/1608.04644.pdf</li>
      </ul>
      </td>
      <td><a href="https://www.youtube.com/watch?v=EkY9GGGCLhA&list=PLkFD6_40KJIxH03tTW2HNSHbgcfTDGKV1&index=2&t=0s">Video</a></td>
      <td></td>
    </tr>
    <tr>
      <td>09/04</td>
      <td>Trevor Darrell</td>
      <td><u>Main Reading:</u>
      <ul>
      <li>https://arxiv.org/abs/1704.05526</li>
      </ul>
      <u>Background Reading:</u>
      <ul>
      <li>https://arxiv.org/abs/1601.01705</li>
      </ul>
      </td>
      <td><a href="https://www.youtube.com/watch?v=GSPgK5GrsIM&i?ijkey=2oZLdw.mS6h5k&keytype=ref&siteid=scindex=2&list=PLkFD6_40KJIxH03tTW2HNSHbgcfTDGKV1">Video</a></td>
      <td></td>
    </tr>
    <tr>
      <td>09/11</td>
      <td>Coline Devin</td>
      <td><u>Main Reading:</u>
      <ul>
	<li>https://arxiv.org/abs/1708.04225</li>
      <li>https://arxiv.org/abs/1609.07088</li>
      </ul>
      <u>Background Reading:</u>
      <ul>
      <li>https://arxiv.org/abs/1509.06113</li>
      </ul>
      </td>
      <td><a href="https://www.youtube.com/watch?v=94o64zdcLmA&list=PLkFD6_40KJIxH03tTW2HNSHbgcfTDGKV1&index=3&t=50s">Video</a></td>
      <td></td>
    </tr>
    <tr>
      <td>09/18</td>
      <td>Amir Zamir</td>
      <td><u>Main Reading:</u>
      <ul>
	<li><a href="http://taskonomy.stanford.edu/taskonomy_CVPR2018.pdf">Taskonomy</a></li>
	<li><a href="https://arxiv.org/abs/1704.06888">Time Contrastive Networks</a></li>
      </ul>
      <u>Background Reading:</u>
      <ul>
	<li><a href="https://arxiv.org/abs/1505.05192">https://arxiv.org/abs/1505.05192</a></li>
	<li><a href="https://arxiv.org/abs/1403.6382">https://arxiv.org/abs/1403.6382</a></li>
      </ul>
      </td>
      <td><a href="https://www.youtube.com/watch?v=3QuRmtIuIpM&list=PLkFD6_40KJIxH03tTW2HNSHbgcfTDGKV1&index=4">Video</a></td>
	    <td></td>
	</tr>
      <tr>
      <td>09/25</td>
      <td>Fisher Yu</td>
      <td><u>Main Reading:</u>
      <ul>
      <li><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Yu_Dilated_Residual_Networks_CVPR_2017_paper.pdf">Dilated Residual Networks</a></li>
      <li><a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Yu_Deep_Layer_Aggregation_CVPR_2018_paper.pdf">Deep Layer Aggregation</a></li>
      </ul>
      <u>Background Reading:</u>
      <ul>
      <li><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf">Fully Convolutional Networks for Semantic Segmentation</a></li>
	<li><a href="https://arxiv.org/abs/1511.07122">Multi-Scale Context Aggregation by Dilated Convolutions</a></li>
      </ul>
      </td>
      <td><a href="https://www.youtube.com/watch?v=nQCSCFXVJuA&index=5&list=PLkFD6_40KJIxH03tTW2HNSHbgcfTDGKV1">Video></a></td>
      <td></td>
  </tr>
   <tr>
      <td>10/2</td>
      <td>Michael Yartsev: Cancelled, replaced by Lisa Hendricks</td>
      <td><u>Main Reading:</u>
      <ul>
      <li></li>
      </ul>
      <u>Background Reading:</u>
      <ul>
      <li></li>
      </ul>
      </td>
      <td><a href="https://www.youtube.com/watch?v=_gx3GM1L8hI&index=6&list=PLkFD6_40KJIxH03tTW2HNSHbgcfTDGKV1">Video</a></td>
      <td></td>
    </tr>
<tr>
      <td>10/9</td>
      <td>David Dohan and Adams yu</td>
      <td><u>Main Reading:</u>
      <ul>
	<li><a href="https://arxiv.org/abs/1804.09541">QANet</a></li>
	<li><a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">Attention is all you need</a></li>
      </ul>
      <u>Background Reading:</u>
      <ul>
	<li><a href="https://allennlp.org/elmo">ELMO</a></li>
	<li><a href="http://jalammar.github.io/illustrated-transformer/">Illustrated Transformer</a></li>
      </ul>
      </td>
      <td><a href="https://www.youtube.com/watch?v=Qc6P0xCUlw4&index=7&list=PLkFD6_40KJIxH03tTW2HNSHbgcfTDGKV1">Video</a></td>
      <td></td>
    </tr>
  <tr>
      <td>10/16</td>
      <td>Lydia Liu</td>
      <td><u>Main Reading:</u>
      <ul>
	<li><a href="https://arxiv.org/abs/1803.04383">DelayedImpact of Fair Machine Learning</a></li>
      </ul>
      <u>Background Reading:</u>
      <ul>
	<li><a href="https://arxiv.org/abs/1610.07524">Fair prediction with disparate impact</a></li>
	<li><a href="https://arxiv.org/abs/1610.02413">Equality of Opportunity in Supervised Learning</a></li>
      </ul>
      </td>
      <td><a href="https://www.youtube.com/watch?v=gUL-5AAJnlU&index=8&list=PLkFD6_40KJIxH03tTW2HNSHbgcfTDGKV1">Video</a></td>
      <td></td>
    </tr>
  <tr>
      <td>10/23</td>
      <td>Larry Zitnick</td>
      <td><u>Main Reading:</u>
      <ul>
      <li><a href="https://dl.dropboxusercontent.com/s/293tu0hh9ww08co/r-cnn-cvpr.pdf?dl=0">Rich Feature Hierarchies</a></li>
	<li><a href="https://arxiv.org/pdf/1703.06870">Mask RCNN</a></li>
      </ul>
      <u>Background Reading:</u>
      <ul>
	<li><a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning</a></li>
      </ul>
      </td>
      <td><a href="https://www.youtube.com/watch?v=inRApAtKXm4&index=10&list=PLkFD6_40KJIxH03tTW2HNSHbgcfTDGKV1">Video</a></td>
      <td></td>
    </tr>
  <tr>
      <td>10/30</td>
      <td>Chris Olah</td>
      <td><u>Main Reading:</u>
      <ul>
	  <li><a href="https://distill.pub/2017/feature-visualization/">Feature Visualization</a></li>
	  <li><a href="https://distill.pub/2018/building-blocks/">Building Blocks of Interpretability</a></li>
      </ul>
      <u>Background Reading:</u>
      <ul>
      <li></li>
      </ul>
      </td>
      <td>Not yet available</td>
      <td></td>
  </tr>
  <tr>
      <td>11/06</td>
      <td>Richard Zhang</td>
      <td><u>Main Reading:</u>
      <ul>
	      <li><a href="https://arxiv.org/abs/1603.08511">Colorful Image Colorization</a></li>
	      <li><a href="http://arxiv.org/abs/1801.03924">The Unreasonable Effectiveness of Deep Features as a Perceptual Metric</a></li>
      </ul>
      <u>Background Reading:</u>
      <ul>
      <li><a href="https://arxiv.org/abs/1711.11586">Toward Multimodal Image-to-Image Translation</a></li>
	      <li><a href="https://arxiv.org/abs/1705.02999">Real-Time User-Guided Image Colorization</a></li>
      </ul>
      </td>
      <td>Not yet available</td>
      <td></td>
    </tr>
    <tr>
      <td>11/13</td>
      <td>Michael Yartsev</td>
      <td><u>Main Reading:</u>
      <ul>
      <li><a href="http://science.sciencemag.org/content/sci/358/6362/466.full.pdf?ijkey=2oZLdw.mS6h5k&keytype=ref&siteid=sci">Paper 1</a></li>
	<li><a href="http://science.sciencemag.org/content/340/6130/367">Paper 2</a></li>
      </ul>
      <u>Background Reading:</u>
      <ul>
      <li><a href="http://www.yossiyovel.com/images/PDF-Files/Prat%20Taub%20Yovel0415.pdf">Paper 3</a></li>
	<li><a href="http://www.yossiyovel.com/images/PDF-Files/PratAzoulayYovel2017.pdf">Paper 4</a></li>
      </ul>
      </td>
      <td>Not yet available</td>
      <td></td>
    </tr>
	   <tr>
      <td>11/20</td>
      <td>No Speaker for Thanksgiving Holiday</td>
      <td>
      </td>
      <td></td>
      <td></td>
    </tr>
   <tr>
      <td>11/27</td>
      <td>Anne Collins</td>
      <td><u>Main Reading:</u>
      <ul>
       <li><a href="https://berkeley-deep-learning.github.io/cs294-131-f18/Collins2018BookChapter.pdf">Book Chapter</a></li>
	      <li><a href="https://berkeley-deep-learning.github.io/cs294-131-f18/Collins2018_JoCN.pdf">Collins2018_JoCN</a></li>
      </ul>
      <u>Background Reading:</u>
      <ul>
      <li></li>
      </ul>
      </td>
      <td>Not yet available</td>
      <td></td>
    </tr>
</tbody>
</table>


## Course description

In recent years, deep learning has enabled huge progress in many domains
including computer vision, speech, NLP, and robotics. It has become the leading
solution for many tasks, from winning the ImageNet competition to winning at Go
against a world champion. This class is designed to help students develop a
deeper understanding of deep learning and explore new research directions and
applications of deep learning. It assumes that students already have a basic
understanding of deep learning. In particular, we will explore a selected list
of new, cutting-edge topics in deep learning, including new techniques and
architectures in deep learning, security and privacy issues in deep learning,
recent advances in the theoretical and systems aspects of deep learning, and new
application domains of deep learning such as autonomous driving.

## Class format and project

This is a lecture, discussion, and project oriented class. Each lecture will
focus on one of the topics, including a survey of the state-of-the-art in the
area and an in-depth discussion of the topic. Each week, students are expected
to complete reading assignments before class and participate actively in class
discussion.

Students will also form project groups (two to three people per group) and
complete a research-quality class project.

## Enrollment information

**For undergraduates**: Please note that this is a graduate-level class.
However, with instructors' permission, we do allow qualified undergraduate
students to be in the class. If you are an undergraduate student and would like
to enroll in the class, please fill out
[**this form**](https://goo.gl/forms/l8x4gwzrVu70ksE13)
and come to the first lecture of the class. Qualified undergraduates will be
given instructor codes to be allowed to register for the class after the first
lecture of the class, subject to space availability.

If you have not received grades for some classes that you are currently enrolled
in, please choose **Currently Enrolled** and then update the form when you
receive your final grades. You may also be interested in [this
class](https://people.eecs.berkeley.edu/~jfc/DeepLearn.html), which is open to
undergraduates.

Students may enroll in this class for variable units.

* **1 unit:** Participate in reading assignments.
* **2 units:** Both reading assignments and a project. Projects may fall into one of
  four categories:
  * Distill-like Literature Review of a deep learning topic (e.g., a Distill-like blog post illustrating different optimization techniques used in deep learning)
  * Reimplement research code and open source it
  * Conference level research project
* You **may not** take this class for **3 or 4 units**.

## Deadlines

* Reading assignment deadlines:
  * Submit questions about the reading material by Monday noon.
* Project deadlines:
  * Project proposal: Friday October 12, 2018, 11:59pm
  * Project Milestone: Friday November 16, 2018, 11:59pm
  * Final write up: December 10, 2018, 11:59pm
  * Project presentations: (Tentative) December 14, 2018

## Grading
* 20% class participation
* 25% weekly reading assignment
* 55% project

## Additional Notes
* For students who need computing resources for the class project, we recommend you to look into AWS educate program for students. You'll get 100 dollar's worth of sign up credit. Here's the <a href="https://aws.amazon.com/education/awseducate/apply/"> link </a>.
